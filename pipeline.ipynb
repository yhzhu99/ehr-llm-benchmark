{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yhzhu/miniconda3/envs/med/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import lightning as L\n",
    "from lightning.pytorch.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from lightning.pytorch.loggers import CSVLogger\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader, SequentialSampler, RandomSampler\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "\n",
    "from utils.classification_metrics import get_binary_metrics, check_metric_is_better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset class\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data_path, mode='train'):\n",
    "        super().__init__()\n",
    "        self.data = pd.read_pickle(os.path.join(data_path, f\"embed_{mode}.pkl\"))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x = self.data[index]['embedding'].float()\n",
    "        y = self.data[index]['label'].float()\n",
    "        return x, y\n",
    "\n",
    "\n",
    "class MyDataModule(L.LightningDataModule):\n",
    "    def __init__(self, batch_size, data_path):\n",
    "        # data_path is like \"logs/embeddings/OpenBioLLM/noteevent/embed_test.pkl\"\n",
    "        super().__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.train_dataset = MyDataset(data_path, mode=\"train\")\n",
    "        self.val_dataset = MyDataset(data_path, mode='valid')\n",
    "        self.test_dataset = MyDataset(data_path, mode='test')\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset, batch_size=self.batch_size, shuffle=True, num_workers=8)\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_dataset, batch_size=self.batch_size, shuffle=False, num_workers=8)\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_dataset, batch_size=self.batch_size, shuffle=False, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Head(nn.Module):\n",
    "    def __init__(self, hidden_dim, output_dim=1, drop=0.1):\n",
    "        super().__init__()\n",
    "        self.proj = nn.Sequential(\n",
    "            nn.Dropout(drop),\n",
    "            nn.Linear(hidden_dim, output_dim),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.proj(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pipeline(L.LightningModule):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = config[\"hidden_dim\"]\n",
    "        self.learning_rate = config[\"learning_rate\"]\n",
    "        self.output_dim = 1\n",
    "\n",
    "        self.model = Head(self.hidden_dim, self.output_dim)\n",
    "        self.loss_fn = nn.BCELoss()\n",
    "\n",
    "        self.cur_best_performance = {} # val set\n",
    "        self.test_performance = {} # test set\n",
    "\n",
    "        self.validation_step_outputs = []\n",
    "        self.test_step_outputs = []\n",
    "        self.test_outputs = {}\n",
    "\n",
    "\n",
    "    def forward(self, batch):\n",
    "        x, y = batch\n",
    "        y_hat = self.model(x).to(x.device)\n",
    "        return y_hat\n",
    "\n",
    "    def _get_loss(self, batch):\n",
    "        x, y = batch\n",
    "        y_hat = self(batch)\n",
    "        loss = self.loss_fn(y_hat, y)\n",
    "        return loss, y_hat\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss, y_hat = self._get_loss(batch)\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        loss, y = batch\n",
    "        loss, y_hat = self._get_loss(batch)\n",
    "        self.log(\"val_loss\", loss)\n",
    "        outs = {'y_pred': y_hat, 'y_true': y, 'val_loss': loss}\n",
    "        self.validation_step_outputs.append(outs)\n",
    "        return loss\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        y_pred = torch.cat([x['y_pred'] for x in self.validation_step_outputs]).detach().cpu()\n",
    "        y_true = torch.cat([x['y_true'] for x in self.validation_step_outputs]).detach().cpu()\n",
    "        loss = torch.stack([x['val_loss'] for x in self.validation_step_outputs]).mean().detach().cpu()\n",
    "        self.log(\"val_loss_epoch\", loss)\n",
    "\n",
    "        metrics = get_binary_metrics(y_pred, y_true)\n",
    "        for k, v in metrics.items(): self.log(k, v)\n",
    "\n",
    "        main_metric = \"auroc\"\n",
    "        main_score = metrics[main_metric]\n",
    "        if check_metric_is_better(self.cur_best_performance, main_score, main_metric):\n",
    "            self.cur_best_performance = metrics\n",
    "            for k, v in metrics.items(): self.log(\"best_\"+k, v)\n",
    "        self.validation_step_outputs.clear()\n",
    "        return main_score\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        loss, y = batch\n",
    "        loss, y_hat = self._get_loss(batch)\n",
    "        self.log(\"test_loss\", loss)\n",
    "        outs = {'y_pred': y_hat, 'y_true': y, 'test_loss': loss}\n",
    "        self.test_step_outputs.append(outs)\n",
    "        return loss\n",
    "\n",
    "    def on_test_epoch_end(self):\n",
    "        y_pred = torch.cat([x['y_pred'] for x in self.test_step_outputs]).detach().cpu()\n",
    "        y_true = torch.cat([x['y_true'] for x in self.test_step_outputs]).detach().cpu()\n",
    "        loss = torch.stack([x['test_loss'] for x in self.test_step_outputs]).mean().detach().cpu()\n",
    "        self.log(\"test_loss_epoch\", loss)\n",
    "\n",
    "        test_performance = get_binary_metrics(y_pred, y_true)\n",
    "        for k, v in test_performance.items(): self.log(\"test_\"+k, v)\n",
    "\n",
    "        self.test_outputs = {'y_pred': y_pred, 'y_true': y_true, 'test_loss': loss}\n",
    "        self.test_step_outputs.clear()\n",
    "\n",
    "        self.test_performance = test_performance\n",
    "        return test_performance\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(self.parameters(), lr=self.learning_rate)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(config):\n",
    "    # data\n",
    "    dm = MyDataModule(batch_size=config[\"batch_size\"], data_path=f\"logs/embeddings/{config['model']}/{config['task']}/\")\n",
    "\n",
    "    # logger\n",
    "    logger = CSVLogger(save_dir=\"logs\", name=f\"{config['model']}\", version=f\"{config['task']}\", flush_logs_every_n_steps=1)\n",
    "\n",
    "    # EarlyStop and checkpoint callback\n",
    "    early_stopping_callback = EarlyStopping(monitor=\"auroc\", patience=config[\"patience\"], mode=\"max\")\n",
    "    checkpoint_callback = ModelCheckpoint(filename=\"best\", monitor=\"auroc\", mode=\"max\")\n",
    "\n",
    "    L.seed_everything(42) # seed for reproducibility\n",
    "\n",
    "    # train/val/test\n",
    "    pipeline = Pipeline(config)\n",
    "    trainer = L.Trainer(accelerator=\"gpu\", devices=[0], max_epochs=config[\"epochs\"], logger=logger, callbacks=[early_stopping_callback, checkpoint_callback])\n",
    "    trainer.fit(pipeline, dm)\n",
    "\n",
    "    # Load best model checkpoint\n",
    "    best_model_path = checkpoint_callback.best_model_path\n",
    "    print(\"best_model_path:\", best_model_path)\n",
    "    pipeline = Pipeline.load_from_checkpoint(best_model_path, config=config)\n",
    "    trainer.test(pipeline, dm)\n",
    "\n",
    "    perf = pipeline.test_performance\n",
    "    outs = pipeline.test_outputs\n",
    "    return perf, outs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 4050 Laptop GPU') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type    | Params\n",
      "------------------------------------\n",
      "0 | model   | Head    | 769   \n",
      "1 | loss_fn | BCELoss | 0     \n",
      "------------------------------------\n",
      "769       Trainable params\n",
      "0         Non-trainable params\n",
      "769       Total params\n",
      "0.003     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yhzhu/miniconda3/envs/med/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py:293: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30: 100%|██████████| 1/1 [00:00<00:00,  1.75it/s, v_num=vent]\n",
      "best_model_path: logs/OpenBioLLM/noteevent/checkpoints/best.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 21.78it/s] \n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "      test_accuracy         0.9900000095367432\n",
      "       test_auprc                   1.0\n",
      "       test_auroc                   1.0\n",
      "         test_f1            0.9892473220825195\n",
      "        test_loss           0.2811698913574219\n",
      "     test_loss_epoch        0.2811698913574219\n",
      "       test_minpse                  1.0\n",
      "     test_precision          0.978723406791687\n",
      "       test_recall                  1.0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.9900000095367432,\n",
       " 'auroc': 1.0,\n",
       " 'auprc': 1.0,\n",
       " 'f1': 0.9892473220825195,\n",
       " 'precision': 0.978723406791687,\n",
       " 'recall': 1.0,\n",
       " 'minpse': 1.0}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {\n",
    "    'model': 'OpenBioLLM',\n",
    "    'task': 'noteevent', # ['noteevent', 'discharge']\n",
    "    'hidden_dim': 768, # ClinicalLongformer embedding\n",
    "    'learning_rate': 1e-4,\n",
    "    'batch_size': 256,\n",
    "    'epochs': 50,\n",
    "    'patience': 5,\n",
    "}\n",
    "\n",
    "perf, outs = run_experiment(config)\n",
    "\n",
    "print(perf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "med",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
